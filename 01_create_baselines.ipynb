{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from utils import get_aws_profile_name, get_aws_iam_role\n",
    "\n",
    "LOCAL_EXECUTION = True\n",
    "\n",
    "if LOCAL_EXECUTION:\n",
    "    sess = boto3.Session(profile_name=get_aws_profile_name())\n",
    "    sm = sess.client(\"sagemaker\")\n",
    "    iam = sess.client('iam')\n",
    "    role = iam.get_role(RoleName=get_aws_iam_role())['Role']['Arn']\n",
    "else:\n",
    "    sess = boto3.Session()\n",
    "    sm = sess.client(\"sagemaker\")\n",
    "    role = sagemaker.get_execution_role()\n",
    "\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"model-monitor-bring-your-own-model/\"\n",
    "region = sess.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data_prefix = prefix + \"data-quality/baseline_input_data\"\n",
    "baseline_results_prefix = prefix + \"data-quality/baseline_results\"\n",
    "\n",
    "baseline_process_model_prefix = prefix + \"data-quality/preprocess_model_data\"\n",
    "baseline_model_prefix = prefix + \"data-quality/model_data\"\n",
    "\n",
    "\n",
    "baseline_data_uri = \"s3://{}/{}\".format(bucket, baseline_data_prefix)\n",
    "baseline_results_uri = \"s3://{}/{}\".format(bucket, baseline_results_prefix)\n",
    "\n",
    "\n",
    "sagemaker_session.upload_data(\n",
    "    path=\"data/train_data_no_target.csv\", bucket=bucket, key_prefix=baseline_data_prefix\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Data Quality Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "my_default_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "my_default_monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_data_uri+'/train_data_no_target.csv',\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "baseline_job = my_default_monitor.latest_baselining_job\n",
    "schema_df = pd.io.json.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "schema_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_df = pd.io.json.json_normalize(\n",
    "    baseline_job.suggested_constraints().body_dict[\"features\"]\n",
    ")\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_job.outputs[0].destination\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save baselines in the config file for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_baseline\n",
    "\n",
    "save_baseline('data-quality-constraints', os.path.join(baseline_job.outputs[0].destination, \"constraints.json\"))\n",
    "save_baseline('data-quality-statistics', os.path.join(baseline_job.outputs[0].destination, \"statistics.json\"))\n",
    "save_baseline('data-quality-baseline-data', baseline_data_uri+'/train_data_no_target.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Quality Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import ModelQualityMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "\n",
    "model_quality_monitor = ModelQualityMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data_prefix = prefix + \"model-quality/baseline_input_data\"\n",
    "baseline_results_prefix = prefix + \"model-quality/baseline_results\"\n",
    "\n",
    "baseline_data_uri = \"s3://{}/{}\".format(bucket, baseline_data_prefix)\n",
    "baseline_results_uri = \"s3://{}/{}\".format(bucket, baseline_results_prefix)\n",
    "\n",
    "\n",
    "sagemaker_session.upload_data(\n",
    "    path=\"data/train_data_with_prediction.csv\", bucket=bucket, key_prefix=baseline_data_prefix\n",
    ")\n",
    "\n",
    "job = model_quality_monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_data_uri, # The S3 location of the validation dataset.\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri = baseline_results_uri, # The S3 location to store the results.\n",
    "    problem_type='BinaryClassification',\n",
    "    inference_attribute= \"prediction\", # The column in the dataset that contains predictions.\n",
    "    probability_attribute= \"prediction_probability\", # The column in the dataset that contains probabilities.\n",
    "    ground_truth_attribute= \"credit_risk\" # The column in the dataset that contains ground truth labels.\n",
    ")\n",
    "job.wait(logs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_job = model_quality_monitor.latest_baselining_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_baseline('model-quality-constraints', os.path.join(baseline_job.outputs[0].destination, \"constraints.json\"))\n",
    "save_baseline('model-quality-statistics', os.path.join(baseline_job.outputs[0].destination, \"statistics.json\"))\n",
    "save_baseline('model-quality-baseline-data', baseline_data_uri+'train_data_with_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(baseline_job.suggested_constraints().body_dict[\"binary_classification_constraints\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Explainability baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create processor model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.model import Model\n",
    "\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\"sklearn\", region, \"0.23-1\")\n",
    "model_name = \"sm-preprocess-model-for-explainability\"\n",
    "dataset_type = \"text/csv\"\n",
    "model_url = sagemaker_session.upload_data(\n",
    "    path=\"data/processed/model.tar.gz\", bucket=bucket, key_prefix=baseline_process_model_prefix\n",
    ")\n",
    "\n",
    "preprocessing_model = Model(\n",
    "    role=role,\n",
    "    name=model_name,\n",
    "    image_uri=image_uri,\n",
    "    model_data=model_url,\n",
    "    entry_point=\"inference_preprocessing.py\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data/trained/ && tar czvf model.tar.gz model.bin\n",
    "\n",
    "from sagemaker.model import Model\n",
    "\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.3-1\")\n",
    "model_name = \"sm-model-for-explainability\"\n",
    "dataset_type = \"text/csv\"\n",
    "\n",
    "model_url = sagemaker_session.upload_data(\n",
    "    path=\"data/trained/model.tar.gz\", bucket=bucket, key_prefix=baseline_model_prefix\n",
    ")\n",
    "\n",
    "xgboost_model = Model(\n",
    "    role=role,\n",
    "    name=model_name,\n",
    "    image_uri=image_uri,\n",
    "    model_data=model_url,\n",
    "    entry_point=\"inference.py\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pipeline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pipeline import PipelineModel\n",
    "\n",
    "\n",
    "model_name = \"e2e-model\"\n",
    "\n",
    "\n",
    "pipeline_model = PipelineModel(\n",
    "    name=model_name,\n",
    "    role=role,\n",
    "    models=[preprocessing_model, xgboost_model],\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "pipeline_model.create(instance_type=\"ml.m5.large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import ModelExplainabilityMonitor\n",
    "from sagemaker.clarify import DataConfig, SHAPConfig, ModelConfig\n",
    "import pandas as pd\n",
    "# from sagemaker.xgboost.model import XGBoostModel\n",
    "\n",
    "baseline_data_prefix = prefix + \"model-explainability/baseline_input_data\"\n",
    "baseline_results_prefix = prefix + \"model-explainability/baseline_results\"\n",
    "\n",
    "baseline_data_uri = \"s3://{}/{}\".format(bucket, baseline_data_prefix)\n",
    "baseline_results_uri = \"s3://{}/{}\".format(bucket, baseline_results_prefix)\n",
    "\n",
    "# input_data_uri = sagemaker_session.upload_data(\n",
    "#     path=\"data/train_data_no_target.csv\", bucket=bucket, key_prefix=baseline_data_prefix\n",
    "# )\n",
    "input_data_uri = sagemaker_session.upload_data(\n",
    "    path=\"data/train.csv\", bucket=bucket, key_prefix=baseline_data_prefix\n",
    ")\n",
    "\n",
    "\n",
    "test_dataframe = pd.read_csv(\"data/train.csv\")\n",
    "all_headers = list(test_dataframe.columns)\n",
    "label_header = \"credit_risk\"\n",
    "# all_headers.remove(label_header)\n",
    "\n",
    "# shap_baseline = [list(test_dataframe.drop(label_header, axis=1).mean())]\n",
    "shap_baseline = [list(test_dataframe.drop(label_header, axis=1).mode().iloc[0].values.astype(int))]\n",
    "\n",
    "shap_baseline = [[ int(i) for i in shap_baseline[0]]]\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    model_name=model_name,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    content_type=dataset_type,\n",
    "    accept_type=dataset_type,\n",
    ")\n",
    "\n",
    "model_explainability_monitor = ModelExplainabilityMonitor(\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    max_runtime_in_seconds=1800,\n",
    ")\n",
    "\n",
    "model_explainability_data_config = DataConfig(\n",
    "    s3_data_input_path=input_data_uri,\n",
    "    s3_output_path=baseline_results_uri,\n",
    "    label=label_header,\n",
    "    headers=all_headers,\n",
    "    dataset_type=dataset_type,\n",
    ")\n",
    "\n",
    "shap_config = SHAPConfig(\n",
    "    baseline=shap_baseline,\n",
    "    num_samples=100,\n",
    "    agg_method=\"mean_abs\",\n",
    "    save_local_shap_values=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_explainability_monitor.suggest_baseline(\n",
    "    data_config=model_explainability_data_config,\n",
    "    model_config=model_config,\n",
    "    explainability_config=shap_config,\n",
    "    wait=True\n",
    ")\n",
    "print(\n",
    "    f\"ModelExplainabilityMonitor baselining job: {model_explainability_monitor.latest_baselining_job_name}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_explainability_monitor.latest_baselining_job.wait(logs=False)\n",
    "model_explainability_constraints = model_explainability_monitor.suggested_constraints()\n",
    "print()\n",
    "print(\n",
    "    f\"ModelExplainabilityMonitor suggested constraints: {model_explainability_constraints.file_s3_uri}\"\n",
    ")\n",
    "print(sagemaker.s3.S3Downloader.read_file(model_explainability_constraints.file_s3_uri, sagemaker_session))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_baseline\n",
    "baseline_job = model_explainability_monitor.latest_baselining_job\n",
    "save_baseline('model-explainability-analysis', os.path.join(baseline_job.outputs[0].destination, \"analysis.json\"))\n",
    "save_baseline('model-explainability-analysis_config', os.path.join(baseline_job.outputs[0].destination, \"analysis_config.json\"))\n",
    "save_baseline('model-explainability-baseline-data', input_data_uri) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Bias Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Followig cell is identical with cell in Explainability baseline section above as its a common step\n",
    "# only changing model name \n",
    "\n",
    "from sagemaker.model import Model\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\"sklearn\", region, \"0.23-1\")\n",
    "model_name = \"sm-preprocess-model-for-bias\"\n",
    "dataset_type = \"text/csv\"\n",
    "model_url = sagemaker_session.upload_data(\n",
    "    path=\"data/processed/model.tar.gz\", bucket=bucket, key_prefix=baseline_process_model_prefix\n",
    ")\n",
    "\n",
    "preprocessing_model = Model(\n",
    "    role=role,\n",
    "    name=model_name,\n",
    "    image_uri=image_uri,\n",
    "    model_data=model_url,\n",
    "    entry_point=\"inference_preprocessing.py\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Followig cell is identical with cell in Explainability baseline section above as its a common step\n",
    "# only changing model name \n",
    "\n",
    "!cd data/trained/ && tar czvf model.tar.gz model.bin\n",
    "\n",
    "from sagemaker.model import Model\n",
    "\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.3-1\")\n",
    "model_name = \"sm-model-for-bias\"\n",
    "dataset_type = \"text/csv\"\n",
    "\n",
    "model_url = sagemaker_session.upload_data(\n",
    "    path=\"data/trained/model.tar.gz\", bucket=bucket, key_prefix=baseline_model_prefix\n",
    ")\n",
    "\n",
    "xgboost_model = Model(\n",
    "    role=role,\n",
    "    name=model_name,\n",
    "    image_uri=image_uri,\n",
    "    model_data=model_url,\n",
    "    entry_point=\"inference.py\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pipeline import PipelineModel\n",
    "\n",
    "\n",
    "model_name = \"e2e-model-bias\"\n",
    "\n",
    "\n",
    "pipeline_model = PipelineModel(\n",
    "    name=model_name,\n",
    "    role=role,\n",
    "    models=[preprocessing_model, xgboost_model],\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "pipeline_model.create(instance_type=\"ml.m5.large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import ModelBiasMonitor\n",
    "from sagemaker.clarify import DataConfig, BiasConfig, ModelConfig\n",
    "import pandas as pd\n",
    "# from sagemaker.xgboost.model import XGBoostModel\n",
    "\n",
    "baseline_data_prefix = prefix + \"model-bias/baseline_input_data\"\n",
    "baseline_results_prefix = prefix + \"model-bias/baseline_results\"\n",
    "\n",
    "baseline_data_uri = \"s3://{}/{}\".format(bucket, baseline_data_prefix)\n",
    "baseline_results_uri = \"s3://{}/{}\".format(bucket, baseline_results_prefix)\n",
    "\n",
    "\n",
    "input_data_uri = sagemaker_session.upload_data(\n",
    "    path=\"data/train.csv\", bucket=bucket, key_prefix=baseline_data_prefix\n",
    ")\n",
    "\n",
    "test_dataframe = pd.read_csv(\"data/train.csv\")\n",
    "all_headers = list(test_dataframe.columns)\n",
    "label_header = \"credit_risk\"\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    model_name=model_name,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    content_type=dataset_type,\n",
    "    accept_type=dataset_type,\n",
    ")\n",
    "\n",
    "model_bias_monitor = ModelBiasMonitor(\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    max_runtime_in_seconds=1800,\n",
    ")\n",
    "\n",
    "model_bias_data_config = DataConfig(\n",
    "    s3_data_input_path=input_data_uri,\n",
    "    s3_output_path=baseline_results_uri,\n",
    "    label=label_header,\n",
    "    headers=all_headers,\n",
    "    dataset_type=dataset_type,\n",
    ")\n",
    "\n",
    "# BiasConfig is the configuration of the sensitive groups in the dataset. \n",
    "# Typically, bias is measured by computing a metric and comparing it across groups. \n",
    "# The group of interest is specified using the “facet.” \n",
    "bias_config = BiasConfig(\n",
    "    label_values_or_threshold=[1],\n",
    "    facet_name=\"foreign_worker\",\n",
    "    facet_values_or_threshold=[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bias_monitor.suggest_baseline(\n",
    "    data_config=model_bias_data_config,\n",
    "    model_config=model_config,\n",
    "    bias_config=bias_config,\n",
    "    wait=True\n",
    ")\n",
    "print(\n",
    "    f\"ModelBiasMonitor baselining job: {model_bias_monitor.latest_baselining_job_name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bias_monitor.latest_baselining_job.wait(logs=False)\n",
    "model_bias_constraints = model_bias_monitor.suggested_constraints()\n",
    "print()\n",
    "print(\n",
    "    f\"ModelBiasMonitor suggested constraints: {model_bias_constraints.file_s3_uri}\"\n",
    ")\n",
    "print(sagemaker.s3.S3Downloader.read_file(model_bias_constraints.file_s3_uri, sagemaker_session))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_baseline\n",
    "baseline_job = model_bias_monitor.latest_baselining_job\n",
    "save_baseline('model-bias-analysis', os.path.join(baseline_job.outputs[0].destination, \"analysis.json\"))\n",
    "save_baseline('model-bias-analysis_config', os.path.join(baseline_job.outputs[0].destination, \"analysis_config.json\"))\n",
    "save_baseline('model-bias-baseline-data', input_data_uri) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT DELETE the model as the model object is going to be used when running ME Check, No costs are being incurred by the model object\n",
    "# pipeline_model.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_model.deploy(initial_instance_count=1, instance_type=\"ml.m5.large\", endpoint_name=\"manual-endpoint9\")\n",
    "# s = \"1,18,4,2,1049,1,2,4,2,1,4,2,21,3,1,1,3,2,1,2\"    \n",
    "# predictor = sagemaker.Predictor(\"manual-endpoint9\", sagemaker_session=sagemaker_session, serializer=sagemaker.serializers.CSVSerializer(),deserializer=sagemaker.deserializers.CSVDeserializer(), )\n",
    "# predictor.predict(s)\n",
    "# predictor.delete_endpoint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('mm-byom')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  4 2020, 02:22:02) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66d769f68ed4c84a07e23de83cd77438094586f02a1789a3dfa9b143f2e1d947"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
